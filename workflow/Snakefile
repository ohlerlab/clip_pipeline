# The main entry point of your workflow.
# After configuring config.yaml and samples.tsv, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.

import os
from os import path
from glob import glob
import sys
import pandas as pd
from snakemake.utils import validate

# Variable for the source code directory
# Allows this workflow to be deployable directly from github
CODE_DIR = workflow.basedir

# Main configuration file
# It will be copied to the target directory of where the workflow is deployed to
configfile: "config/config.yaml"

# Samplesheet (uses path to samples.tsv defined in config.yaml)
samples = pd.read_csv(config["samples"], sep="\t").set_index("sample", drop=False)
samples.index.names = ["sample_id"]

# Validation schema for the samplesheet
validate(samples, schema=workflow.source_path("schemas/samples.schema.yaml"))

# Global directives
report: workflow.source_path("report/workflow.rst")
# Add a default value for bash executable if config is not set
shell.executable(config.get("SHELL_EXEC", "/bin/bash"))

# Allow users to fix the underlying OS via singularity.
container: "docker://continuumio/miniconda3"

# Modular rules
include: workflow.source_path("rules/process_reads.smk")
include: workflow.source_path("rules/align_reads.smk")
include: workflow.source_path("rules/call_peaks.smk")
include: workflow.source_path("rules/other.smk")
include: workflow.source_path("rules/common.smk")
## To Do :add strand invertion rule


# The first rule should define the default target files
# Subsequent target rules can be specified below. They should start with all_*.
rule all:
    input:
       	expand(rules.omniclip_run.output, sample=samples.index),
        expand(rules.paralyzer.output, sample=samples.index)

