# This file should contain everything to configure the workflow on a global scale.
# In case of sample based data, it should be complemented by a samples.tsv file that contains
# one row per sample. It can be parsed easily via pandas.
samples: "config/samples.tsv"

SHELL_EXEC:
  "/bin/bash"
REFERENCE_GENOME:
  "/fast/AG_Ohler/Rene/clip_project/hg19/gencode/GRCh37.p13.genome.fa"
UMI-BARCODE:
  "(?P<umi_1>.{4}).*(?P<umi_2>.{4})$"
THREE_PRIME_ADAPTER_SEQUENCE:
  "TGGAATTCTCGGGTGCCAAGG"
FIVE_PRIME_ADAPTER_SEQUENCE:
  "AATGATACGGCGACCACCGACAGGTTCAGAGTTCTACAGTCCGACGATC"
NINETEEN_NUCLEOTIDE_MARKER_SEQUENCE:
  "CGTACGCGGGTTTAAACGA"
TWENTY_FOUR_NUCLEOTIDE_MARKER_SEQUENCE:
  "CGTACGCGGAATAGTTTAAACTGT"
ICLIP_ADAPTER:
  "AGATCGGAAGAGCGGTTCAG"
HITSCLIP_3ADAPTER:
  "TCGTATGCCGTCTTCTGCTTG"
HITSCLIP_5ADAPTER:
  "AATGATACGGCGACCACCGA"
KIT_5ADAPTER:
  "GTTCAGAGTTCTACAGTCCGACGATC"
SPECIAL_AD_1:
  "AGATCGGAAGAGCACACGTCTG"
SPECIAL_AD_2:
  "CTCGTATGCCGTCTTCTGCTTG"
SPECIAL_AD_3:
  "TGAGATCGGAAGAGCGGTTCAG"
THR:
  "8"
GTF:
  "/fast/AG_Ohler/svetlana/Genomes/hg19/gencode/annotation/gencode.v19.annotation.gtf"


call_peaks:
  BANDWIDTH: 3
  CONVERSION: T>C
  MINIMUM_READ_COUNT_PER_GROUP: 5
  MINIMUM_READ_COUNT_PER_CLUSTER: 5
  MINIMUM_READ_COUNT_FOR_KDE: 5
  MINIMUM_CLUSTER_SIZE: 8
  MINIMUM_CONVERSION_LOCATIONS_FOR_CLUSTER: 1
  MINIMUM_CONVERSION_COUNT_FOR_CLUSTER: 1
  MINIMUM_READ_COUNT_FOR_CLUSTER_INCLUSION: 5
  MINIMUM_READ_LENGTH: 13
  MAXIMUM_NUMBER_OF_NON_CONVERSION_MISMATCHES: 0

  OUTPUT_DISTRIBUTIONS_FILE: ".distribution"
  OUTPUT_GROUPS_FILE: ".groups"
  OUTPUT_CLUSTERS_FILE: ".clusters"
  OUTPUT_READS_FILE: "_PARalyzer_Utilized.sam"

  EXTEND_BY_READ: True
  HAFFNER_APPROACH: False
  ADDITIONAL_NUCLEOTIDES_BEYOND_SIGNAL: 0
